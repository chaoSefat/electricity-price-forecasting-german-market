{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_for_EPF_2.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eeE2rJRk4rnx"},"source":["# EPF using LSTM"]},{"cell_type":"markdown","metadata":{"id":"_qOZOx0Y424D"},"source":["## Importing packages"]},{"cell_type":"code","metadata":{"id":"Xo-YN8rpe7AB"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error,r2_score"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D2is__7x47Wh"},"source":["## Data processing and loading"]},{"cell_type":"code","metadata":{"id":"NH2JjQmM4mSB"},"source":[" from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mRTACtnU4mYK"},"source":["dir = \"drive/MyDrive/Colab_Notebooks/data_\"\n","prices_df = pd.read_csv(dir+\"/prices.csv\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B386kriGV5XJ"},"source":["prices_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uYkOBsmKVx9o"},"source":["print(len(pd.isna(prices_df[\"prices\"])==False))\n","print(len(prices_df[\"prices\"]))\n","print(3*365*24)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-HJDMZtMXY-H"},"source":["df_test = prices_df.iloc[:92*24,:]\n","print(df_test.head())\n","df_test.plot(x='dates', y='prices')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jm9mVwANaGTs"},"source":["l = df_test['dates'].unique()\n","print(len(df_test['prices'])==92*24)\n","prices_arr = df_test.values\n","print(len(prices_arr[prices_arr==0]))\n","print(len(l))\n","print(l)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QHCaCntT4maf"},"source":["prices_arr = prices_df.iloc[:,2].values\n","print(type(prices_arr))\n","#plt.plot(training_set, label = 'Shampoo Sales Data')\n","plt.figure(figsize=(20, 6), dpi=80)\n","plt.plot(prices_arr, label = 'Electricity Prices')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZgkDaXu4mcl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZnMZQEqX6q4E"},"source":["### Data loading"]},{"cell_type":"code","metadata":{"id":"wdLGt7Wf4me7"},"source":["\"\"\"\"def sliding_windows(data, seq_length):\n","    x = []\n","    y = []\n","\n","    for i in range(len(data)-seq_length-1):\n","        _x = data[i:(i+seq_length)]\n","        _y = data[i+seq_length]\n","        x.append(_x)\n","        y.append(_y)\n","\n","    return np.array(x),np.array(y)\n","\n","sc = MinMaxScaler()\n","training_data = sc.fit_transform(prices_arr.reshape(-1,1))\n","\n","seq_length = 24\n","x, y = sliding_windows(training_data, seq_length)\n","\n","train_size = int(len(y) * 0.67)\n","test_size = len(y) - train_size\n","\n","dataX = Variable(torch.Tensor(np.array(x)))\n","dataY = Variable(torch.Tensor(np.array(y)))\n","\n","trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n","trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n","\n","testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n","testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))\"\"\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i-qtZMao4mhc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wzk8cHQc4mjT"},"source":["def restructering(data, input_days):\n","    x = []\n","    y = []\n","\n","    day_len = 24\n","    num_hours = len(data)\n","    num_of_days = num_hours//day_len\n","    if (num_hours % day_len != 0):\n","      print(\"something's wrong, I can feel it ! \")\n","    data_ = data.reshape(num_of_days,day_len)\n","    print(data_.shape)\n","    \n","    num_of_lines = len(data_)//input_days\n","    for i in range(num_of_days-input_days):\n","        _x = data_[i:(i+input_days)]\n","        _y = data_[i+input_days]\n","        x.append(_x)\n","        y.append(_y)\n","\n","    return np.array(x),np.array(y)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mv8TmXm4mlr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"USP-6wui4moB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzYg5LbS4mqY"},"source":["\n","sc = MinMaxScaler()\n","training_data = sc.fit_transform(prices_arr.reshape(-1,1))\n","\n","input_days = 5\n","\n","x, y = restructering(training_data, input_days)\n","\n","train_size = int(len(y) * 0.67)\n","test_size = len(y) - train_size\n","\n","dataX = Variable(torch.Tensor(np.array(x)))\n","dataY = Variable(torch.Tensor(np.array(y)))\n","\n","trainX = Variable(torch.Tensor(np.array(x[0:train_size])))\n","trainY = Variable(torch.Tensor(np.array(y[0:train_size])))\n","\n","testX = Variable(torch.Tensor(np.array(x[train_size:len(x)])))\n","testY = Variable(torch.Tensor(np.array(y[train_size:len(y)])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(trainX.shape)\n","print(trainX.size(0))"],"metadata":{"id":"RxA1eb59sxiQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pubt8tEb5GDv"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"ZncLhfIP4msu"},"source":["class LSTM(nn.Module):\n","\n","    def __init__(self, num_classes, input_size, hidden_size, num_layers):\n","        super(LSTM, self).__init__()\n","        \n","        self.num_classes = num_classes\n","        self.num_layers = num_layers\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        #self.seq_length = seq_length\n","        \n","        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n","                            num_layers=num_layers, batch_first=True)\n","        \n","        self.fc = nn.Linear(hidden_size, num_classes)\n","\n","    def forward(self, x):\n","        h_0 = Variable(torch.zeros(\n","            self.num_layers, x.size(0), self.hidden_size))\n","        \n","        c_0 = Variable(torch.zeros(\n","            self.num_layers, x.size(0), self.hidden_size))\n","        \n","        # Propagate input through LSTM\n","        ula, (h_out, _) = self.lstm(x, (h_0, c_0))\n","        \n","        h_out = h_out.view(-1, self.hidden_size)\n","        \n","        out = self.fc(h_out)\n","        \n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UYhQ0DRo4mvB"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hVdaMkh97HOQ"},"source":["## Training"]},{"cell_type":"code","metadata":{"id":"an2dQ82j4mxp"},"source":["num_epochs = 3000\n","learning_rate = 0.001\n","\n","input_size = 24\n","hidden_size = 100\n","num_layers = 1\n","\n","num_classes = 24\n","\n","lstm = LSTM(num_classes, input_size, hidden_size, num_layers)\n","\n","criterion = torch.nn.MSELoss()    # mean-squared error for regression\n","optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n","\n","# Train the model\n","for epoch in range(num_epochs):\n","    outputs = lstm(trainX)\n","    optimizer.zero_grad()\n","    \n","    # obtain the loss function\n","    loss = criterion(outputs, trainY)\n","    \n","    loss.backward()\n","    \n","    optimizer.step()\n","    if epoch % 100 == 0:\n","      print(\"Epoch: %d, loss: %1.5f\" % (epoch, loss.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BnADmtV4nCW"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7OHC85PK4nFG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kUU63kPy5I_3"},"source":["## Evaluation"]},{"cell_type":"code","metadata":{"id":"ZImjzmve5Lrc"},"source":["lstm.eval()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"odfs5-uu5LlN"},"source":["pred_y = lstm(testX)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ik3FqpDZ5Lih"},"source":["print(pred_y.shape)\n","print(testY.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2rRhymIo5K1u"},"source":["plt.plot(pred_y[6].detach().numpy())\n","plt.plot(testY[6].detach().numpy())\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(20, 6), dpi=80)\n","fig, axs = plt.subplots(2,2)\n","\n","fig.suptitle('real vs predication')\n","for i in range(2):\n","  for j in range(2):\n","    axs[i, j].plot(pred_y[i+j].detach().numpy())\n","    axs[i, j].plot(testY[i+j].detach().numpy())\n","\n"],"metadata":{"id":"DxNiMu0NxMjr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","fig, axs = plt.subplots(6,6)\n","fig.set_figheight(15)\n","fig.set_figwidth(15)\n","fig.suptitle('real vs predication')\n","for i in range(6):\n","  for j in range(6):\n","    tmp_pred = sc.inverse_transform(pred_y[5+i+j].detach().numpy().reshape(-1,1))\n","    tmp_real = sc.inverse_transform(testY[5+i+j].detach().numpy().reshape(-1,1))\n","    axs[i, j].plot(tmp_pred)\n","    axs[i, j].plot(tmp_real)"],"metadata":{"id":"SgZKXB_G_uBe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_mse = 0\n","total_mape = 0\n","total_r2 = 0\n","test_len = len(testY)\n","\n","for i in range (test_len):\n","  total_mse += mean_squared_error(pred_y[i].detach().numpy(),testY[i].detach().numpy())\n","  total_mape += mean_absolute_percentage_error(pred_y[i].detach().numpy(),testY[i].detach().numpy())\n","  total_r2 += r2_score(pred_y[i].detach().numpy(),testY[i].detach().numpy())\n","\n","print(\"mse:\" , total_mse/test_len )\n","print(\"total_mape:\" , total_mape/test_len )\n","print(\"total_r2:\" , total_r2/test_len )"],"metadata":{"id":"r97RLynCyKCQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"_a3GqUESyJ_1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","print(tmp_pred)\n","print(tmp_real)"],"metadata":{"id":"N7_T4yuNyJ83"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"OX175VecyJ5s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"qTBlN-QdyJ3B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"jSQ_mznzyJbW"},"execution_count":null,"outputs":[]}]}